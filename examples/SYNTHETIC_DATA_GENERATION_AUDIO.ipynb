{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b22ab170-1a9b-4f4f-b48c-ed1ea5c03208",
   "metadata": {
    "name": "cell1",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# TextToSpeech Class Demonstration\n",
    "\n",
    "This notebook demonstrates the capabilities of the TextToSpeech class for generating synthetic audio data. We'll cover both simple single-speaker text-to-speech and complex multi-speaker dialogue scenarios.\n",
    "\n",
    "## Features Demonstrated\n",
    "1. **Single Speaker TTS** - Basic text-to-speech conversion\n",
    "2. **Multi-Speaker Dialogues** - Complex conversations with multiple voices  \n",
    "3. **Call Center Example** - Realistic customer service interaction\n",
    "4. **Random Speaker Assignment** - Automatic voice selection for characters\n",
    "5. **Snowflake Integration** - Saving audio files to Snowflake stages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1fd962-8878-4c7b-9949-fdb0ebfc0e76",
   "metadata": {
    "name": "cell2",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's import the necessary modules and set up our TextToSpeech instances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62de886-2920-41ce-bd55-416d7269cb39",
   "metadata": {
    "language": "python",
    "name": "cell19"
   },
   "outputs": [],
   "source": [
    "# install libraries\n",
    "!pip install --quiet --root-user-action=ignore coqui-tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53928f9b-10a0-4877-9468-29e88716b906",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": [
    "# Append parent directory to sys.path for relative imports\n",
    "import sys\n",
    "sys.path.append('/home/app')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import streamlit as st\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "\n",
    "from audio.text_to_speech import TextToSpeech\n",
    "from audio.voices import VOICES\n",
    "\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")\n",
    "print(f\"Available models in VOICES: {list(VOICES.keys())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10af5760-6167-4893-818d-b57a9b4e5afd",
   "metadata": {
    "name": "cell4",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Example 1: Simple Single-Speaker Text-to-Speech\n",
    "\n",
    "Let's start with a basic example using a fast single-speaker model. This is perfect for generating simple announcements or narrations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57fac05-e367-4e91-85a3-0e7f0ce5034f",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": [
    "# Initialize a fast single-speaker TTS model\n",
    "print(\"üîÑ Loading single-speaker TTS model...\")\n",
    "tts_simple = TextToSpeech(model=\"tts_models/en/ljspeech/tacotron2-DDC\")\n",
    "print(\"‚úÖ Model loaded successfully!\")\n",
    "\n",
    "# Generate simple text-to-speech\n",
    "text = \"Welcome to our synthetic data generation platform. This audio was created using advanced text-to-speech technology.\"\n",
    "\n",
    "print(f\"üé§ Generating speech for: '{text}'\")\n",
    "audio_data = tts_simple.text_to_speech(text)\n",
    "\n",
    "print(f\"‚úÖ Audio generated! Shape: {audio_data.shape}, Duration: {len(audio_data)/tts_simple.sample_rate:.2f} seconds\")\n",
    "\n",
    "# Play the audio in the notebook\n",
    "st.audio(audio_data, sample_rate=tts_simple.sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dca059-6af1-42dd-9ed4-d9678ceda7f7",
   "metadata": {
    "name": "cell6",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Example 2: Multi-Speaker Dialogue - Call Center Scenario\n",
    "\n",
    "Now let's create a more complex example with multiple speakers. We'll simulate a customer service call with realistic dialogue between a representative and a customer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddfa702-607f-4b33-9456-29fc625cbe77",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": [
    "# Initialize multi-speaker, multilingual TTS model\n",
    "print(\"üîÑ Loading multi-speaker TTS model (this may take a moment)...\")\n",
    "tts_dialogue = TextToSpeech(model=\"tts_models/multilingual/multi-dataset/xtts_v2\")\n",
    "print(\"‚úÖ Multi-speaker model loaded successfully!\")\n",
    "\n",
    "# Let's explore the available speakers\n",
    "print(f\"\\nüì¢ Total available speakers: {len(tts_dialogue.tts_model.speakers)}\")\n",
    "print(\"üé≠ Sample female voices:\", VOICES[\"tts_models/multilingual/multi-dataset/xtts_v2\"][\"female_voices\"][:5])\n",
    "print(\"üé≠ Sample male voices:\", VOICES[\"tts_models/multilingual/multi-dataset/xtts_v2\"][\"male_voices\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9da64a-4a02-44b4-9511-9907defbd9fb",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": [
    "# Create a realistic call center dialogue\n",
    "call_center_dialogue = {\n",
    "    \"segments\": [\n",
    "        {\n",
    "            \"text\": \"Thank you for calling TechCorp customer service. This is Sarah speaking. How can I help you today?\",\n",
    "            \"speaker\": \"Representative\"\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Hi Sarah, I'm having trouble with my recent order. I placed it three days ago but haven't received any tracking information.\",\n",
    "            \"speaker\": \"Customer\"\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"I'm sorry to hear that you're experiencing this issue. Let me look up your order right away. Can you please provide me with your order number?\",\n",
    "            \"speaker\": \"Representative\"\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Sure, it's order number T-C-K-2-0-2-4-dash-7-8-9-1.\",\n",
    "            \"speaker\": \"Customer\"\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Perfect, thank you. I can see your order here. It looks like there was a slight delay in processing, but I have good news - your order was shipped yesterday and should arrive tomorrow. Let me send you the tracking number right now.\",\n",
    "            \"speaker\": \"Representative\"\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Oh that's great! Thank you so much for checking on that. I really appreciate your help.\",\n",
    "            \"speaker\": \"Customer\"\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"You're very welcome! Is there anything else I can help you with today?\",\n",
    "            \"speaker\": \"Representative\"\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"No, that takes care of everything. Thank you again, Sarah.\",\n",
    "            \"speaker\": \"Customer\"\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"My pleasure! Have a wonderful day and thank you for choosing TechCorp.\",\n",
    "            \"speaker\": \"Representative\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"üìù Call center dialogue script created!\")\n",
    "print(f\"üí¨ Total segments: {len(call_center_dialogue['segments'])}\")\n",
    "for i, segment in enumerate(call_center_dialogue['segments'], 1):\n",
    "    print(f\"  {i}. {segment['speaker']}: {segment['text'][:50]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748cfa63-b06b-4f98-bbd9-ec4820afaac1",
   "metadata": {
    "name": "cell9",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Version A: Manual Speaker Assignment\n",
    "\n",
    "First, let's create the dialogue with manually chosen speakers for each role.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cf1897-8951-4e6e-ac02-66437556a304",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": [
    "# Create dialogue with specific speaker assignment\n",
    "# Map our character names to actual TTS voices\n",
    "manual_dialogue = {\n",
    "    \"segments\": []\n",
    "}\n",
    "\n",
    "for segment in call_center_dialogue[\"segments\"]:\n",
    "    new_segment = segment.copy()\n",
    "    if segment[\"speaker\"] == \"Representative\":\n",
    "        new_segment[\"speaker\"] = \"Claribel Dervla\"  # Professional female voice for rep\n",
    "    elif segment[\"speaker\"] == \"Customer\": \n",
    "        new_segment[\"speaker\"] = \"Andrew Chipper\"   # Friendly male voice for customer\n",
    "    manual_dialogue[\"segments\"].append(new_segment)\n",
    "\n",
    "print(\"üé§ Generating call center dialogue with manual speaker assignment...\")\n",
    "print(\"üë©‚Äçüíº Representative: Claribel Dervla (female)\")\n",
    "print(\"üë®‚Äçüíª Customer: Andrew Chipper (male)\")\n",
    "\n",
    "dialogue_audio_manual = tts_dialogue.create_dialogue(\n",
    "    manual_dialogue, \n",
    "    language=\"en\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Dialogue generated! Duration: {len(dialogue_audio_manual)/tts_dialogue.sample_rate:.1f} seconds\")\n",
    "\n",
    "# Play the dialogue\n",
    "st.audio(dialogue_audio_manual, sample_rate=tts_dialogue.sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348bc9fd-a32f-4005-a508-1a19d5ac013b",
   "metadata": {
    "name": "cell11",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Version B: Random Speaker Assignment\n",
    "\n",
    "Now let's try the same dialogue with automatic random speaker assignment. This feature automatically assigns voices to characters, alternating between male and female voices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1885e9b-8150-4f72-a433-8ffe39d02552",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": [
    "# Generate the same dialogue with random speaker assignment\n",
    "print(\"üé≤ Generating call center dialogue with random speaker assignment...\")\n",
    "print(\"üîÑ The system will automatically assign voices, alternating gender between speakers\")\n",
    "\n",
    "dialogue_audio_random = tts_dialogue.create_dialogue(\n",
    "    call_center_dialogue,  # Using original dialogue with character names\n",
    "    language=\"en\",\n",
    "    random_speaker=True    # Enable automatic voice assignment\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Random dialogue generated! Duration: {len(dialogue_audio_random)/tts_dialogue.sample_rate:.1f} seconds\")\n",
    "print(\"üé≠ Each character was automatically assigned a voice from the available pool\")\n",
    "\n",
    "# Play the random-assigned dialogue\n",
    "st.audio(dialogue_audio_random, sample_rate=tts_dialogue.sample_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046fd0d6-5b1d-48ce-91da-5c708f963112",
   "metadata": {
    "collapsed": false,
    "name": "cell13",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Example 3: Snowflake Integration\n",
    "\n",
    "The TextToSpeech class can directly save generated audio files to Snowflake stages. \n",
    "\n",
    "**Note**: The following example requires an active Snowflake session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65feef6-235d-45d6-855b-0f6c33449db4",
   "metadata": {
    "language": "python",
    "name": "cell14"
   },
   "outputs": [],
   "source": [
    "# Example of saving to Snowflake stage (requires active session)\n",
    "session = get_active_session()\n",
    "\n",
    "# Check if we have an active Snowflake session\n",
    "session = tts_dialogue.check_session()\n",
    "print(\"‚úÖ Active Snowflake session found!\")\n",
    "\n",
    "# Generate audio and save directly to stage\n",
    "announcement_text = \"This audio file was generated automatically and saved to Snowflake stage.\"\n",
    "\n",
    "print(\"üé§ Generating audio and saving to Snowflake stage...\")\n",
    "audio_with_stage = tts_dialogue.text_to_speech(\n",
    "    text=announcement_text,\n",
    "    speaker=\"Sofia Hellen\",\n",
    "    language=\"en\",\n",
    "    stage_location=\"@AUDIO/generated_announcement.wav\"  # Adjust stage name as needed\n",
    ")\n",
    "\n",
    "print(\"üîä Downloading audio file from Snowflake stage and play it.\")\n",
    "staged_audio_file = session.file.get_stream('@AUDIO/generated_announcement.wav')\n",
    "st.audio(staged_audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9941be2-4ec0-4141-afdc-53d67b3ab2f0",
   "metadata": {
    "name": "cell15",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Example 4: Saving Audio Files Locally\n",
    "\n",
    "You can also save the generated audio files locally for further processing or analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac26c8-b57b-443f-84fd-e6f85749e9fa",
   "metadata": {
    "language": "python",
    "name": "cell16"
   },
   "outputs": [],
   "source": [
    "# Save generated audio files locally\n",
    "output_dir = \"generated_audio\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the simple TTS example\n",
    "simple_path = os.path.join(output_dir, \"simple_announcement.wav\")\n",
    "sf.write(simple_path, audio_data, tts_simple.sample_rate)\n",
    "print(f\"üíæ Simple TTS saved to: {simple_path}\")\n",
    "\n",
    "# Save the manual dialogue\n",
    "manual_path = os.path.join(output_dir, \"call_center_manual.wav\")\n",
    "sf.write(manual_path, dialogue_audio_manual, tts_dialogue.sample_rate)\n",
    "print(f\"üíæ Manual dialogue saved to: {manual_path}\")\n",
    "\n",
    "# Save the random dialogue  \n",
    "random_path = os.path.join(output_dir, \"call_center_random.wav\")\n",
    "sf.write(random_path, dialogue_audio_random, tts_dialogue.sample_rate)\n",
    "print(f\"üíæ Random dialogue saved to: {random_path}\")\n",
    "\n",
    "print(f\"\\nüìÅ All audio files saved in '{output_dir}/' directory\")\n",
    "print(\"üéß You can play these files with any audio player or use them in your applications\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f8bbea",
   "metadata": {},
   "source": [
    "# Example 5: Voice Conversion Between Different Speakers\n",
    "\n",
    "This example demonstrates voice conversion, which transforms the voice characteristics of source audio \n",
    "to match a target speaker's voice while preserving the original speech content. This is useful for:\n",
    "- Creating consistent voice branding across different audio content\n",
    "- Voice anonymization for privacy protection\n",
    "- Generating variations of existing audio with different speaker characteristics\n",
    "- Creating personalized voices for accessibility applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26324bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load voice conversion model for converting between different speakers\n",
    "print(\"üîÑ Loading voice conversion model...\")\n",
    "tts_model = TTS(model_name=\"voice_conversion_models/multilingual/vctk/freevc24\", progress_bar=False).to(\"cuda\")\n",
    "\n",
    "# Convert voice from source audio to target speaker's voice\n",
    "print(\"üé≠ Converting voice from source audio to target speaker...\")\n",
    "converted_voice = tts_model.voice_conversion(source_wav='audio/harvard.wav', target_wav='audio/obama_sample1.wav')\n",
    "\n",
    "# Play the converted audio\n",
    "print(\"üîä Playing converted voice audio...\")\n",
    "st.audio(converted_voice, sample_rate=22050)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6198ba10-1bc6-4cdc-97f5-91038560e4d7",
   "metadata": {
    "name": "cell17",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook demonstrated the key capabilities of the TextToSpeech class:\n",
    "\n",
    "### ‚úÖ What We Covered\n",
    "1. **Single-Speaker TTS** - Fast synthesis with `tts_models/en/ljspeech/tacotron2-DDC`\n",
    "2. **Multi-Speaker Dialogues** - Complex conversations using `tts_models/multilingual/multi-dataset/xtts_v2`\n",
    "3. **Call Center Simulation** - Realistic customer service interaction\n",
    "4. **Manual vs Random Speaker Assignment** - Different approaches to voice selection\n",
    "5. **Voice Conversion** - Convert voices\n",
    "6. **Snowflake Integration** - Direct saving to Snowflake stages\n",
    "7. **Local File Operations** - Saving audio files for further use\n",
    "\n",
    "### üöÄ Potential Applications\n",
    "- **Customer Service Training**: Generate realistic call center scenarios\n",
    "- **Content Creation**: Automated narration and announcements  \n",
    "- **Data Augmentation**: Create diverse audio datasets for ML training\n",
    "- **Accessibility**: Convert text content to audio for visually impaired users\n",
    "- **Interactive Systems**: Voice interfaces and conversational AI\n",
    "\n",
    "### üîß Advanced Features to Explore\n",
    "- Different TTS models for various languages and voice qualities\n",
    "- Integration with other Snowflake ML features\n",
    "- Batch processing of large text datasets\n",
    "- Custom voice cloning and fine-tuning\n",
    "- Real-time streaming applications\n",
    "\n",
    "### üìö Additional Resources\n",
    "- [Coqui TTS Documentation](https://tts.readthedocs.io/)\n",
    "- [Snowflake ML Documentation](https://docs.snowflake.com/en/developer-guide/snowpark-ml/index)\n",
    "- Check the `voices.py` file for all available voice options\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "lastEditStatus": {
   "authorEmail": "michael.gorkow@snowflake.com",
   "authorId": "5423371114908",
   "authorName": "ADMIN",
   "lastEditTime": 1756172234526,
   "notebookId": "hlycfpa7mwwzfz7ylsun",
   "sessionId": "f4397619-111d-4165-a735-479263dbbca7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
