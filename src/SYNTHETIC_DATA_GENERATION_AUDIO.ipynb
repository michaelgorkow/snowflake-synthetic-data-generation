{
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "lastEditStatus": {
   "notebookId": "hlycfpa7mwwzfz7ylsun",
   "authorId": "5423371114908",
   "authorName": "ADMIN",
   "authorEmail": "michael.gorkow@snowflake.com",
   "sessionId": "f4397619-111d-4165-a735-479263dbbca7",
   "lastEditTime": 1756172234526
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b22ab170-1a9b-4f4f-b48c-ed1ea5c03208",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "cell1"
   },
   "source": [
    "# TextToSpeech Class Demonstration\n",
    "\n",
    "This notebook demonstrates the capabilities of the TextToSpeech class for generating synthetic audio data. We'll cover both simple single-speaker text-to-speech and complex multi-speaker dialogue scenarios.\n",
    "\n",
    "## Features Demonstrated\n",
    "1. **Single Speaker TTS** - Basic text-to-speech conversion\n",
    "2. **Multi-Speaker Dialogues** - Complex conversations with multiple voices  \n",
    "3. **Call Center Example** - Realistic customer service interaction\n",
    "4. **Random Speaker Assignment** - Automatic voice selection for characters\n",
    "5. **Snowflake Integration** - Saving audio files to Snowflake stages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1fd962-8878-4c7b-9949-fdb0ebfc0e76",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "cell2"
   },
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's import the necessary modules and set up our TextToSpeech instances.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "f62de886-2920-41ce-bd55-416d7269cb39",
   "metadata": {
    "language": "python",
    "name": "cell19"
   },
   "outputs": [],
   "source": "# install libraries\n!pip install --quiet --root-user-action=ignore coqui-tts",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53928f9b-10a0-4877-9468-29e88716b906",
   "metadata": {
    "name": "cell3",
    "language": "python"
   },
   "outputs": [],
   "source": "import sys\nimport os\nimport numpy as np\nimport soundfile as sf\nimport streamlit as st\nfrom snowflake.snowpark.context import get_active_session\n\nfrom audio.text_to_speech import TextToSpeech\nfrom audio.voices import VOICES\n\n\nprint(\"‚úÖ Imports successful!\")\nprint(f\"Available models in VOICES: {list(VOICES.keys())}\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "10af5760-6167-4893-818d-b57a9b4e5afd",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "cell4"
   },
   "source": [
    "## Example 1: Simple Single-Speaker Text-to-Speech\n",
    "\n",
    "Let's start with a basic example using a fast single-speaker model. This is perfect for generating simple announcements or narrations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57fac05-e367-4e91-85a3-0e7f0ce5034f",
   "metadata": {
    "name": "cell5",
    "language": "python"
   },
   "outputs": [],
   "source": "# Initialize a fast single-speaker TTS model\nprint(\"üîÑ Loading single-speaker TTS model...\")\ntts_simple = TextToSpeech(model=\"tts_models/en/ljspeech/tacotron2-DDC\")\nprint(\"‚úÖ Model loaded successfully!\")\n\n# Generate simple text-to-speech\ntext = \"Welcome to our synthetic data generation platform. This audio was created using advanced text-to-speech technology.\"\n\nprint(f\"üé§ Generating speech for: '{text}'\")\naudio_data = tts_simple.text_to_speech(text)\n\nprint(f\"‚úÖ Audio generated! Shape: {audio_data.shape}, Duration: {len(audio_data)/tts_simple.sample_rate:.2f} seconds\")\n\n# Play the audio in the notebook\nst.audio(audio_data, sample_rate=tts_simple.sample_rate)"
  },
  {
   "cell_type": "markdown",
   "id": "73dca059-6af1-42dd-9ed4-d9678ceda7f7",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "cell6"
   },
   "source": [
    "## Example 2: Multi-Speaker Dialogue - Call Center Scenario\n",
    "\n",
    "Now let's create a more complex example with multiple speakers. We'll simulate a customer service call with realistic dialogue between a representative and a customer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddfa702-607f-4b33-9456-29fc625cbe77",
   "metadata": {
    "name": "cell7",
    "language": "python"
   },
   "outputs": [],
   "source": "# Initialize multi-speaker, multilingual TTS model\nprint(\"üîÑ Loading multi-speaker TTS model (this may take a moment)...\")\ntts_dialogue = TextToSpeech(model=\"tts_models/multilingual/multi-dataset/xtts_v2\")\nprint(\"‚úÖ Multi-speaker model loaded successfully!\")\n\n# Let's explore the available speakers\nprint(f\"\\nüì¢ Total available speakers: {len(tts_dialogue.tts_model.speakers)}\")\nprint(\"üé≠ Sample female voices:\", VOICES[\"tts_models/multilingual/multi-dataset/xtts_v2\"][\"female_voices\"][:5])\nprint(\"üé≠ Sample male voices:\", VOICES[\"tts_models/multilingual/multi-dataset/xtts_v2\"][\"male_voices\"][:5])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9da64a-4a02-44b4-9511-9907defbd9fb",
   "metadata": {
    "name": "cell8",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Create a realistic call center dialogue\n",
    "call_center_dialogue = {\n",
    "    \"segments\": [\n",
    "        {\n",
    "            \"text\": \"Thank you for calling TechCorp customer service. This is Sarah speaking. How can I help you today?\",\n",
    "            \"speaker\": \"Representative\"\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Hi Sarah, I'm having trouble with my recent order. I placed it three days ago but haven't received any tracking information.\",\n",
    "            \"speaker\": \"Customer\"\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"I'm sorry to hear that you're experiencing this issue. Let me look up your order right away. Can you please provide me with your order number?\",\n",
    "            \"speaker\": \"Representative\"\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Sure, it's order number T-C-K-2-0-2-4-dash-7-8-9-1.\",\n",
    "            \"speaker\": \"Customer\"\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Perfect, thank you. I can see your order here. It looks like there was a slight delay in processing, but I have good news - your order was shipped yesterday and should arrive tomorrow. Let me send you the tracking number right now.\",\n",
    "            \"speaker\": \"Representative\"\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Oh that's great! Thank you so much for checking on that. I really appreciate your help.\",\n",
    "            \"speaker\": \"Customer\"\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"You're very welcome! Is there anything else I can help you with today?\",\n",
    "            \"speaker\": \"Representative\"\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"No, that takes care of everything. Thank you again, Sarah.\",\n",
    "            \"speaker\": \"Customer\"\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"My pleasure! Have a wonderful day and thank you for choosing TechCorp.\",\n",
    "            \"speaker\": \"Representative\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"üìù Call center dialogue script created!\")\n",
    "print(f\"üí¨ Total segments: {len(call_center_dialogue['segments'])}\")\n",
    "for i, segment in enumerate(call_center_dialogue['segments'], 1):\n",
    "    print(f\"  {i}. {segment['speaker']}: {segment['text'][:50]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748cfa63-b06b-4f98-bbd9-ec4820afaac1",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "cell9"
   },
   "source": [
    "### Version A: Manual Speaker Assignment\n",
    "\n",
    "First, let's create the dialogue with manually chosen speakers for each role.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cf1897-8951-4e6e-ac02-66437556a304",
   "metadata": {
    "name": "cell10",
    "language": "python"
   },
   "outputs": [],
   "source": "# Create dialogue with specific speaker assignment\n# Map our character names to actual TTS voices\nmanual_dialogue = {\n    \"segments\": []\n}\n\nfor segment in call_center_dialogue[\"segments\"]:\n    new_segment = segment.copy()\n    if segment[\"speaker\"] == \"Representative\":\n        new_segment[\"speaker\"] = \"Claribel Dervla\"  # Professional female voice for rep\n    elif segment[\"speaker\"] == \"Customer\": \n        new_segment[\"speaker\"] = \"Andrew Chipper\"   # Friendly male voice for customer\n    manual_dialogue[\"segments\"].append(new_segment)\n\nprint(\"üé§ Generating call center dialogue with manual speaker assignment...\")\nprint(\"üë©‚Äçüíº Representative: Claribel Dervla (female)\")\nprint(\"üë®‚Äçüíª Customer: Andrew Chipper (male)\")\n\ndialogue_audio_manual = tts_dialogue.create_dialogue(\n    manual_dialogue, \n    language=\"en\"\n)\n\nprint(f\"‚úÖ Dialogue generated! Duration: {len(dialogue_audio_manual)/tts_dialogue.sample_rate:.1f} seconds\")\n\n# Play the dialogue\nst.audio(dialogue_audio_manual, sample_rate=tts_dialogue.sample_rate)"
  },
  {
   "cell_type": "markdown",
   "id": "348bc9fd-a32f-4005-a508-1a19d5ac013b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "cell11"
   },
   "source": [
    "### Version B: Random Speaker Assignment\n",
    "\n",
    "Now let's try the same dialogue with automatic random speaker assignment. This feature automatically assigns voices to characters, alternating between male and female voices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1885e9b-8150-4f72-a433-8ffe39d02552",
   "metadata": {
    "name": "cell12",
    "language": "python"
   },
   "outputs": [],
   "source": "# Generate the same dialogue with random speaker assignment\nprint(\"üé≤ Generating call center dialogue with random speaker assignment...\")\nprint(\"üîÑ The system will automatically assign voices, alternating gender between speakers\")\n\ndialogue_audio_random = tts_dialogue.create_dialogue(\n    call_center_dialogue,  # Using original dialogue with character names\n    language=\"en\",\n    random_speaker=True    # Enable automatic voice assignment\n)\n\nprint(f\"‚úÖ Random dialogue generated! Duration: {len(dialogue_audio_random)/tts_dialogue.sample_rate:.1f} seconds\")\nprint(\"üé≠ Each character was automatically assigned a voice from the available pool\")\n\n# Play the random-assigned dialogue\nst.audio(dialogue_audio_random, sample_rate=tts_dialogue.sample_rate)\n"
  },
  {
   "cell_type": "markdown",
   "id": "046fd0d6-5b1d-48ce-91da-5c708f963112",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "cell13",
    "collapsed": false
   },
   "source": "## Example 3: Snowflake Integration\n\nThe TextToSpeech class can directly save generated audio files to Snowflake stages. \n\n**Note**: The following example requires an active Snowflake session.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65feef6-235d-45d6-855b-0f6c33449db4",
   "metadata": {
    "name": "cell14",
    "language": "python"
   },
   "outputs": [],
   "source": "# Example of saving to Snowflake stage (requires active session)\nsession = get_active_session()\n\n# Check if we have an active Snowflake session\nsession = tts_dialogue.check_session()\nprint(\"‚úÖ Active Snowflake session found!\")\n\n# Generate audio and save directly to stage\nannouncement_text = \"This audio file was generated automatically and saved to Snowflake stage.\"\n\nprint(\"üé§ Generating audio and saving to Snowflake stage...\")\naudio_with_stage = tts_dialogue.text_to_speech(\n    text=announcement_text,\n    speaker=\"Sofia Hellen\",\n    language=\"en\",\n    stage_location=\"@AUDIO/generated_announcement.wav\"  # Adjust stage name as needed\n)\n\nprint(\"üîä Downloading audio file from Snowflake stage and play it.\")\nstaged_audio_file = session.file.get_stream('@AUDIO/generated_announcement.wav')\nst.audio(staged_audio_file)"
  },
  {
   "cell_type": "markdown",
   "id": "e9941be2-4ec0-4141-afdc-53d67b3ab2f0",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "cell15"
   },
   "source": [
    "## Example 4: Saving Audio Files Locally\n",
    "\n",
    "You can also save the generated audio files locally for further processing or analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac26c8-b57b-443f-84fd-e6f85749e9fa",
   "metadata": {
    "name": "cell16",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Save generated audio files locally\n",
    "output_dir = \"generated_audio\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the simple TTS example\n",
    "simple_path = os.path.join(output_dir, \"simple_announcement.wav\")\n",
    "sf.write(simple_path, audio_data, tts_simple.sample_rate)\n",
    "print(f\"üíæ Simple TTS saved to: {simple_path}\")\n",
    "\n",
    "# Save the manual dialogue\n",
    "manual_path = os.path.join(output_dir, \"call_center_manual.wav\")\n",
    "sf.write(manual_path, dialogue_audio_manual, tts_dialogue.sample_rate)\n",
    "print(f\"üíæ Manual dialogue saved to: {manual_path}\")\n",
    "\n",
    "# Save the random dialogue  \n",
    "random_path = os.path.join(output_dir, \"call_center_random.wav\")\n",
    "sf.write(random_path, dialogue_audio_random, tts_dialogue.sample_rate)\n",
    "print(f\"üíæ Random dialogue saved to: {random_path}\")\n",
    "\n",
    "print(f\"\\nüìÅ All audio files saved in '{output_dir}/' directory\")\n",
    "print(\"üéß You can play these files with any audio player or use them in your applications\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6198ba10-1bc6-4cdc-97f5-91038560e4d7",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "cell17"
   },
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook demonstrated the key capabilities of the TextToSpeech class:\n",
    "\n",
    "### ‚úÖ What We Covered\n",
    "1. **Single-Speaker TTS** - Fast synthesis with `tts_models/en/ljspeech/tacotron2-DDC`\n",
    "2. **Multi-Speaker Dialogues** - Complex conversations using `tts_models/multilingual/multi-dataset/xtts_v2`\n",
    "3. **Call Center Simulation** - Realistic customer service interaction\n",
    "4. **Manual vs Random Speaker Assignment** - Different approaches to voice selection\n",
    "5. **Snowflake Integration** - Direct saving to Snowflake stages\n",
    "6. **Local File Operations** - Saving audio files for further use\n",
    "\n",
    "### üöÄ Potential Applications\n",
    "- **Customer Service Training**: Generate realistic call center scenarios\n",
    "- **Content Creation**: Automated narration and announcements  \n",
    "- **Data Augmentation**: Create diverse audio datasets for ML training\n",
    "- **Accessibility**: Convert text content to audio for visually impaired users\n",
    "- **Interactive Systems**: Voice interfaces and conversational AI\n",
    "\n",
    "### üîß Advanced Features to Explore\n",
    "- Different TTS models for various languages and voice qualities\n",
    "- Integration with other Snowflake ML features\n",
    "- Batch processing of large text datasets\n",
    "- Custom voice cloning and fine-tuning\n",
    "- Real-time streaming applications\n",
    "\n",
    "### üìö Additional Resources\n",
    "- [Coqui TTS Documentation](https://tts.readthedocs.io/)\n",
    "- [Snowflake ML Documentation](https://docs.snowflake.com/en/developer-guide/snowpark-ml/index)\n",
    "- Check the `voices.py` file for all available voice options\n"
   ]
  }
 ]
}