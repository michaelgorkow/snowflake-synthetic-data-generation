# Audio Synthesis with TextToSpeech Class

A powerful text-to-speech system that integrates with Snowflake for generating synthetic audio data. Built on top of the Coqui TTS library, this class provides both simple single-speaker synthesis and complex multi-speaker dialogue generation.

## ğŸ¯ Overview

The `TextToSpeech` class wraps the [Coqui TTS library](https://github.com/coqui-ai/TTS) and provides seamless integration with Snowflake Snowpark for saving audio files directly to stages. It supports both single-speaker and multi-speaker scenarios, making it ideal for creating realistic synthetic audio data for training, testing, and content generation.

## âœ¨ Key Features

- **Single & Multi-Speaker Support**: Generate speech with one or multiple distinct voices
- **Voice Conversion**: Transform existing audio to match different speaker characteristics
- **Multilingual Capabilities**: Support for multiple languages depending on the model
- **Snowflake Integration**: Direct saving to Snowflake stages via Snowpark
- **Random Speaker Assignment**: Automatic voice assignment with gender alternation
- **Dialogue Generation**: Create realistic conversations between multiple speakers
- **Robust Error Handling**: Comprehensive validation and informative error messages
- **GPU Acceleration**: Automatic GPU detection and utilization when available

## ğŸš€ Quick Start
See the complete interactive examples in the **[SYNTHETIC_DATA_GENERATION_AUDIO.ipynb](../SYNTHETIC_DATA_GENERATION_AUDIO.ipynb)** notebook

### Basic Text-to-Speech
```python
from audio.text_to_speech import TextToSpeech

# Simple single-speaker TTS
tts = TextToSpeech(model="tts_models/en/ljspeech/tacotron2-DDC")
audio = tts.text_to_speech("Hello, this is a test of text to speech.")
```

### Multi-Speaker Dialogue
```python
# Multi-speaker dialogue with specific voices
tts_dialogue = TextToSpeech(model="tts_models/multilingual/multi-dataset/xtts_v2")
dialogue = {
    "segments": [
        {"text": "Hello, how are you today?", "speaker": "Claribel Dervla"},
        {"text": "I'm doing great, thanks for asking!", "speaker": "Andrew Chipper"},
        {"text": "That's wonderful to hear!", "speaker": "Claribel Dervla"}
    ]
}
audio = tts_dialogue.create_dialogue(dialogue, language="en")
```

### Random Speaker Assignment
```python
# Let the system automatically assign voices
customer_service_call = {
    "segments": [
        {"text": "Thank you for calling TechSupport. How can I help you?", "speaker": "Agent"},
        {"text": "Hi, I'm having issues with my internet connection.", "speaker": "Customer"},
        {"text": "I'd be happy to help you troubleshoot that.", "speaker": "Agent"},
        {"text": "Great! The connection keeps dropping every few minutes.", "speaker": "Customer"}
    ]
}
audio = tts_dialogue.create_dialogue(
    customer_service_call, 
    language="en", 
    random_speaker=True
)
```

### Multilingual Support
```python
# Generate speech in different languages
tts_multi = TextToSpeech(model="tts_models/multilingual/multi-dataset/xtts_v2")

# French
audio_fr = tts_multi.text_to_speech(
    text="Bonjour, comment allez-vous?", 
    speaker="Claribel Dervla", 
    language="fr"
)

# Spanish
audio_es = tts_multi.text_to_speech(
    text="Hola, Â¿cÃ³mo estÃ¡s?", 
    speaker="Andrew Chipper", 
    language="es"
)
```

### Direct Snowflake Integration
```python
# Generate and save directly to Snowflake stage
audio = tts.text_to_speech(
    text="This audio will be saved to Snowflake stage",
    speaker="Sofia Hellen",
    language="en",
    stage_location="@AUDIO_STAGE/meeting_recording.wav"
)

# Save dialogue to stage
dialogue_audio = tts_dialogue.create_dialogue(
    dialogue,
    language="en",
    stage_location="@CUSTOMER_CALLS/support_call_001.wav"
)
```

### Voice Conversion Between Speakers
```python
from TTS.api import TTS

# Load voice conversion model for transforming speaker characteristics
print("ğŸ”„ Loading voice conversion model...")
tts_model = TTS(model_name="voice_conversion_models/multilingual/vctk/freevc24", progress_bar=False)

# Convert voice from source audio to target speaker's voice
# This preserves the speech content but changes the voice characteristics
converted_voice = tts_model.voice_conversion(
    source_wav='audio/sample_files/harvard.wav',     # Source audio file
    target_wav='audio/sample_files/obama_sample1.wav' # Target speaker reference
)

# The result maintains the original speech content but with the target speaker's voice
print("ğŸ­ Voice conversion complete - original content with new speaker characteristics!")
```


## ğŸ­ Available Voices

The system includes predefined voice configurations in `voices.py`. For the `tts_models/multilingual/multi-dataset/xtts_v2` model:

**Female Voices:** Claribel Dervla, Daisy Studious, Gracie Wise, Tammie Ema, Alison Dietlinde, and many more...

**Male Voices:** Ludvig Milivoj, Aaron Dreschner, Ferran Simen, Eugenio MataracÄ±, Andrew Chipper, and many more...

## ğŸŒ Supported Models

### Single-Speaker Models
- `tts_models/en/ljspeech/tacotron2-DDC` - Fast English synthesis
- `tts_models/en/ljspeech/glow-tts` - High-quality English synthesis

### Multi-Speaker Models  
- `tts_models/multilingual/multi-dataset/xtts_v2` - Multilingual, multi-speaker model
- `tts_models/en/vctk/vits` - English multi-speaker model

### Full list of Models

<details>
<summary>Click to expand the complete list of available models</summary>

#### Text-to-Speech Models
These models convert written text into natural-sounding speech audio. They vary in quality, language support, and computational requirements. Single-speaker models generate consistent voice output, while multi-speaker models allow voice selection for different characters or scenarios.

| Model | Multispeaker | Multilanguage | Quality | Languages |
|-------|--------------|---------------|---------|-----------|
| `tts_models/multilingual/multi-dataset/xtts_v2` | âœ… | âœ… | High | 17+ languages |
| `tts_models/multilingual/multi-dataset/xtts_v1.1` | âœ… | âœ… | High | 17+ languages |
| `tts_models/multilingual/multi-dataset/your_tts` | âœ… | âœ… | Medium | 100+ languages |
| `tts_models/multilingual/multi-dataset/bark` | âœ… | âœ… | High | 13+ languages |
| `tts_models/bg/cv/vits` | âŒ | âŒ | Medium | Bulgarian |
| `tts_models/cs/cv/vits` | âŒ | âŒ | Medium | Czech |
| `tts_models/da/cv/vits` | âŒ | âŒ | Medium | Danish |
| `tts_models/et/cv/vits` | âŒ | âŒ | Medium | Estonian |
| `tts_models/ga/cv/vits` | âŒ | âŒ | Medium | Irish |
| `tts_models/en/ek1/tacotron2` | âŒ | âŒ | Medium | English |
| `tts_models/en/ljspeech/tacotron2-DDC` | âŒ | âŒ | High | English |
| `tts_models/en/ljspeech/tacotron2-DDC_ph` | âŒ | âŒ | High | English |
| `tts_models/en/ljspeech/glow-tts` | âŒ | âŒ | High | English |
| `tts_models/en/ljspeech/speedy-speech` | âŒ | âŒ | Medium | English |
| `tts_models/en/ljspeech/tacotron2-DCA` | âŒ | âŒ | High | English |
| `tts_models/en/ljspeech/vits` | âŒ | âŒ | High | English |
| `tts_models/en/ljspeech/vits--neon` | âŒ | âŒ | High | English |
| `tts_models/en/ljspeech/fast_pitch` | âŒ | âŒ | Medium | English |
| `tts_models/en/ljspeech/overflow` | âŒ | âŒ | Medium | English |
| `tts_models/en/ljspeech/neural_hmm` | âŒ | âŒ | Medium | English |
| `tts_models/en/vctk/vits` | âœ… | âŒ | High | English |
| `tts_models/en/vctk/fast_pitch` | âœ… | âŒ | Medium | English |
| `tts_models/en/sam/tacotron-DDC` | âŒ | âŒ | Medium | English |
| `tts_models/en/blizzard2013/capacitron-t2-c50` | âŒ | âŒ | Medium | English |
| `tts_models/en/blizzard2013/capacitron-t2-c150_v2` | âŒ | âŒ | Medium | English |
| `tts_models/en/multi-dataset/tortoise-v2` | âœ… | âŒ | High | English |
| `tts_models/en/jenny/jenny` | âŒ | âŒ | High | English |
| `tts_models/es/mai/tacotron2-DDC` | âŒ | âŒ | Medium | Spanish |
| `tts_models/es/css10/vits` | âŒ | âŒ | Medium | Spanish |
| `tts_models/fr/mai/tacotron2-DDC` | âŒ | âŒ | Medium | French |
| `tts_models/fr/css10/vits` | âŒ | âŒ | Medium | French |
| `tts_models/uk/mai/glow-tts` | âŒ | âŒ | Medium | Ukrainian |
| `tts_models/uk/mai/vits` | âŒ | âŒ | Medium | Ukrainian |
| `tts_models/zh-CN/baker/tacotron2-DDC-GST` | âŒ | âŒ | Medium | Chinese (Mandarin) |
| `tts_models/nl/mai/tacotron2-DDC` | âŒ | âŒ | Medium | Dutch |
| `tts_models/nl/css10/vits` | âŒ | âŒ | Medium | Dutch |
| `tts_models/de/thorsten/tacotron2-DCA` | âŒ | âŒ | Medium | German |
| `tts_models/de/thorsten/vits` | âŒ | âŒ | Medium | German |
| `tts_models/de/thorsten/tacotron2-DDC` | âŒ | âŒ | Medium | German |
| `tts_models/de/css10/vits-neon` | âŒ | âŒ | Medium | German |
| `tts_models/ja/kokoro/tacotron2-DDC` | âŒ | âŒ | Medium | Japanese |
| `tts_models/tr/common-voice/glow-tts` | âŒ | âŒ | Medium | Turkish |
| `tts_models/it/mai_female/glow-tts` | âŒ | âŒ | Medium | Italian |
| `tts_models/it/mai_female/vits` | âŒ | âŒ | Medium | Italian |
| `tts_models/it/mai_male/glow-tts` | âŒ | âŒ | Medium | Italian |
| `tts_models/it/mai_male/vits` | âŒ | âŒ | Medium | Italian |
| `tts_models/ewe/openbible/vits` | âŒ | âŒ | Medium | Ewe |
| `tts_models/hau/openbible/vits` | âŒ | âŒ | Medium | Hausa |
| `tts_models/lin/openbible/vits` | âŒ | âŒ | Medium | Lingala |
| `tts_models/tw_akuapem/openbible/vits` | âŒ | âŒ | Medium | Twi (Akuapem) |
| `tts_models/tw_asante/openbible/vits` | âŒ | âŒ | Medium | Twi (Asante) |
| `tts_models/yor/openbible/vits` | âŒ | âŒ | Medium | Yoruba |
| `tts_models/hu/css10/vits` | âŒ | âŒ | Medium | Hungarian |
| `tts_models/el/cv/vits` | âŒ | âŒ | Medium | Greek |
| `tts_models/fi/css10/vits` | âŒ | âŒ | Medium | Finnish |
| `tts_models/hr/cv/vits` | âŒ | âŒ | Medium | Croatian |
| `tts_models/lt/cv/vits` | âŒ | âŒ | Medium | Lithuanian |
| `tts_models/lv/cv/vits` | âŒ | âŒ | Medium | Latvian |
| `tts_models/mt/cv/vits` | âŒ | âŒ | Medium | Maltese |
| `tts_models/pl/mai_female/vits` | âŒ | âŒ | Medium | Polish |
| `tts_models/pt/cv/vits` | âŒ | âŒ | Medium | Portuguese |
| `tts_models/ro/cv/vits` | âŒ | âŒ | Medium | Romanian |
| `tts_models/sk/cv/vits` | âŒ | âŒ | Medium | Slovak |
| `tts_models/sl/cv/vits` | âŒ | âŒ | Medium | Slovenian |
| `tts_models/sv/cv/vits` | âŒ | âŒ | Medium | Swedish |
| `tts_models/ca/custom/vits` | âŒ | âŒ | Medium | Catalan |
| `tts_models/fa/custom/glow-tts` | âŒ | âŒ | Medium | Persian |
| `tts_models/fa/custom/vits-female` | âŒ | âŒ | Medium | Persian |
| `tts_models/bn/custom/vits-male` | âŒ | âŒ | Medium | Bengali |
| `tts_models/bn/custom/vits-female` | âŒ | âŒ | Medium | Bengali |
| `tts_models/be/common-voice/glow-tts` | âŒ | âŒ | Medium | Belarusian |

#### Vocoder Models
*Vocoders convert spectrograms into raw audio waveforms, improving the quality and naturalness of generated speech. These models work alongside TTS models to produce the final audio output.*

| Model | Language/Region | Architecture | Quality |
|-------|----------------|--------------|---------|
| `vocoder_models/universal/libri-tts/wavegrad` | Universal | WaveGrad | High |
| `vocoder_models/universal/libri-tts/fullband-melgan` | Universal | FullBand MelGAN | High |
| `vocoder_models/en/ek1/wavegrad` | English | WaveGrad | High |
| `vocoder_models/en/librispeech100/wavlm-hifigan` | English | WavLM HiFiGAN | High |
| `vocoder_models/en/librispeech100/wavlm-hifigan_prematched` | English | WavLM HiFiGAN (Pre-matched) | High |
| `vocoder_models/en/ljspeech/multiband-melgan` | English | Multiband MelGAN | High |
| `vocoder_models/en/ljspeech/hifigan_v2` | English | HiFiGAN v2 | High |
| `vocoder_models/en/ljspeech/univnet` | English | UnivNet | High |
| `vocoder_models/en/blizzard2013/hifigan_v2` | English | HiFiGAN v2 | High |
| `vocoder_models/en/vctk/hifigan_v2` | English | HiFiGAN v2 | High |
| `vocoder_models/en/sam/hifigan_v2` | English | HiFiGAN v2 | High |
| `vocoder_models/nl/mai/parallel-wavegan` | Dutch | Parallel WaveGAN | Medium |
| `vocoder_models/de/thorsten/wavegrad` | German | WaveGrad | Medium |
| `vocoder_models/de/thorsten/fullband-melgan` | German | FullBand MelGAN | Medium |
| `vocoder_models/de/thorsten/hifigan_v1` | German | HiFiGAN v1 | Medium |
| `vocoder_models/ja/kokoro/hifigan_v1` | Japanese | HiFiGAN v1 | Medium |
| `vocoder_models/uk/mai/multiband-melgan` | Ukrainian | Multiband MelGAN | Medium |
| `vocoder_models/tr/common-voice/hifigan` | Turkish | HiFiGAN | Medium |
| `vocoder_models/be/common-voice/hifigan` | Belarusian | HiFiGAN | Medium |

#### Voice Conversion Models
*Voice conversion models allow changing the speaker identity of existing audio while preserving the linguistic content. These models can transform one person's voice to sound like another person's voice.*

| Model | Language/Region | Architecture | Quality |
|-------|----------------|--------------|---------|
| `voice_conversion_models/multilingual/vctk/freevc24` | Multilingual | FreeVC | High |
| `voice_conversion_models/multilingual/multi-dataset/knnvc` | Multilingual | k-NN VC | High |
| `voice_conversion_models/multilingual/multi-dataset/openvoice_v1` | Multilingual | OpenVoice v1 | High |
| `voice_conversion_models/multilingual/multi-dataset/openvoice_v2` | Multilingual | OpenVoice v2 | High |
</details>

## ğŸ”§ Advanced Features

### Random Speaker Assignment
When `random_speaker=True` is used in `create_dialogue()`:
- Automatically assigns voices from the predefined voice pool
- Alternates between male and female voices for different speakers
- Ensures consistent voice mapping for the same character throughout the dialogue

### Error Handling
The class provides comprehensive error handling for:
- Invalid model names
- Unsupported speakers or languages
- Missing Snowflake sessions
- Invalid dialogue formats
- Audio generation failures

### GPU Acceleration
- Automatically detects and uses GPU when available
- Falls back gracefully to CPU processing
- Optimal performance for batch processing

## ğŸ“ File Structure

```
audio/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ text_to_speech.py    # Main TextToSpeech class
â”œâ”€â”€ voices.py           # Voice configurations
â””â”€â”€ Readme.md          # This documentation
```

## ğŸ¯ Use Cases

- **Customer Service Training**: Generate realistic call center scenarios
- **Content Creation**: Automated narration and announcements
- **Data Augmentation**: Create diverse audio datasets for ML training
- **Accessibility**: Convert text content to audio
- **Synthetic Data Generation**: Create large-scale audio datasets

## ğŸ“š Additional Resources

- [Complete Interactive Examples](../SYNTHETIC_DATA_GENERATION_AUDIO.ipynb) - Jupyter notebook with hands-on examples
- [Coqui TTS Documentation](https://tts.readthedocs.io/)
